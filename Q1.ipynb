{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using lag first and last functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"event_status\").getOrCreate()\n",
    "# Create input data\n",
    "data = [\n",
    "    ('2020-06-01', 'Won'),\n",
    "    ('2020-06-02', 'Won'),\n",
    "    ('2020-06-03', 'Won'),\n",
    "    ('2020-06-04', 'Lost'),\n",
    "    ('2020-06-05', 'Lost'),\n",
    "    ('2020-06-07', 'Won')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(data,[\"event_date\",\"event_status\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+\n",
      "|event_date|event_status|\n",
      "+----------+------------+\n",
      "|2020-06-01|         Won|\n",
      "|2020-06-02|         Won|\n",
      "|2020-06-03|         Won|\n",
      "|2020-06-04|        Lost|\n",
      "|2020-06-05|        Lost|\n",
      "|2020-06-07|         Won|\n",
      "+----------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"event_date\", col(\"event_date\").cast(\"date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+\n",
      "|event_date|event_status|event_change|\n",
      "+----------+------------+------------+\n",
      "|2020-06-01|         Won|           0|\n",
      "|2020-06-02|         Won|           0|\n",
      "|2020-06-03|         Won|           0|\n",
      "|2020-06-04|        Lost|           1|\n",
      "|2020-06-05|        Lost|           0|\n",
      "|2020-06-07|         Won|           1|\n",
      "+----------+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from pyspark.sql.window import Window\n",
    "df1 = df.withColumn(\"event_change\",when(col(\"event_status\")!=lag(\"event_status\").over(Window.orderBy(\"event_date\")),1).otherwise(0))\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =df1.withColumn(\"event_group\",sum(\"event_change\").over(Window.orderBy(\"event_date\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+------------+-----------+\n",
      "|event_date|event_status|event_change|event_group|\n",
      "+----------+------------+------------+-----------+\n",
      "|2020-06-01|         Won|           0|          0|\n",
      "|2020-06-02|         Won|           0|          0|\n",
      "|2020-06-03|         Won|           0|          0|\n",
      "|2020-06-04|        Lost|           1|          1|\n",
      "|2020-06-05|        Lost|           0|          1|\n",
      "|2020-06-07|         Won|           1|          2|\n",
      "+----------+------------+------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+\n",
      "|event_status|start_date|  end_date|\n",
      "+------------+----------+----------+\n",
      "|         Won|2020-06-01|2020-06-03|\n",
      "|        Lost|2020-06-04|2020-06-05|\n",
      "|         Won|2020-06-07|2020-06-07|\n",
      "+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output_df = df2.groupBy(\"event_group\",\"event_status\")\\\n",
    "                .agg(first(\"event_date\").alias(\"start_date\"),last(\"event_date\").alias(\"end_date\")).drop(\"event_group\")\n",
    "\n",
    "output_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the code in sparksql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"events\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "WITH CTE1 AS (\n",
    "    SELECT\n",
    "        event_date,\n",
    "        event_status,\n",
    "        CASE \n",
    "            WHEN event_status != LAG(event_status) OVER (ORDER BY event_date) \n",
    "            THEN 1 \n",
    "            ELSE 0 \n",
    "        END AS event_change\n",
    "    FROM events\n",
    "),\n",
    "CTE2 AS (\n",
    "    SELECT\n",
    "        event_date,\n",
    "        event_status,\n",
    "        SUM(event_change) OVER (ORDER BY event_date) AS event_group\n",
    "    FROM CTE1\n",
    ")\n",
    "SELECT\n",
    "    event_status,\n",
    "    MIN(event_date) AS start_date,\n",
    "    MAX(event_date) AS end_date\n",
    "FROM CTE2\n",
    "GROUP BY event_group, event_status\n",
    "ORDER BY start_date\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------+----------+\n",
      "|event_status|start_date|  end_date|\n",
      "+------------+----------+----------+\n",
      "|         Won|2020-06-01|2020-06-03|\n",
      "|        Lost|2020-06-04|2020-06-05|\n",
      "|         Won|2020-06-07|2020-06-07|\n",
      "+------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Execute the query and get the result\n",
    "result = spark.sql(query)\n",
    "\n",
    "# Show the result\n",
    "result.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
